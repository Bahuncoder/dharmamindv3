# LLM Gateway Environment Configuration

# Server Configuration
LLM_GATEWAY_HOST=0.0.0.0
LLM_GATEWAY_PORT=8003

# Security
LLM_GATEWAY_API_KEY=llm-gateway-secure-key-change-this-in-production

# Backend Communication
DHARMAMIND_BACKEND_URL=http://localhost:8000

# ğŸ” LLM Gateway - Environment Configuration
# ================================================================
# 
# Secure configuration for the LLM Gateway microservice
# This service handles external API keys (OpenAI, Anthropic)
#
# Generated: 2025-08-17
# ================================================================

# ğŸŒ Environment
ENVIRONMENT=production
DEBUG=false

# ğŸ” Gateway Security
LLM_GATEWAY_API_KEY=q-TMYaRQNGYgs6cjXYj8t_t6OTcSjKl7gL_2zNikUeM

# ğŸ¤– External LLM API Keys (KEEP SECURE!)
OPENAI_API_KEY=your-openai-api-key-here
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# ğŸš€ Server Configuration
HOST=127.0.0.1
PORT=8003

# ğŸ“Š Rate Limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_BURST_SIZE=10

# ğŸ—„ï¸ Cache Configuration
ENABLE_CACHE=true
CACHE_TTL_SECONDS=300

# ğŸ“ Logging
LOG_LEVEL=INFO
LOG_FILE=llm_gateway.log

# ğŸŒ CORS (Allow main backend only)
CORS_ORIGINS=["http://localhost:8000","http://127.0.0.1:8000"]

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60

# Optional: Redis for advanced caching and rate limiting
# REDIS_URL=redis://localhost:6379
